{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from PersianStemmer import PersianStemmer\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ps = PersianStemmer()\n",
    "\n",
    "extra_words = []\n",
    "with open('persian-stopwords/short', encoding='UTF-8') as my_file:\n",
    "    for line in my_file:\n",
    "        extra_words.append(line.replace('\\n', ''))\n",
    "\n",
    "extra_chars = []\n",
    "with open('persian-stopwords/chars', encoding='UTF-8') as my_file:\n",
    "    for line in my_file:\n",
    "        extra_chars.append(line.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_extra_words(string):\n",
    "    string = str(string)\n",
    "    string = ps.run(string)\n",
    "    for char in extra_chars:\n",
    "        string = string.replace(char, ' ')\n",
    "\n",
    "    edit_string_as_list = string.split()\n",
    "\n",
    "    return [word for word in edit_string_as_list if word not in extra_words]\n",
    "    # return edit_string_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    trainData = pd.read_csv('train.csv')\n",
    "    print(\"*************** read csv ***************\")\n",
    "\n",
    "    trainData['title'] = trainData['title'].apply(remove_extra_words)\n",
    "    print(\"*************** remove extra title *****\")\n",
    "\n",
    "    trainData['comment'] = trainData['comment'].apply(remove_extra_words)\n",
    "    print(\"*************** remove extra comment ***\")\n",
    "\n",
    "    verified_title = []\n",
    "    spam_title = []\n",
    "\n",
    "    verified_comment = []\n",
    "    spam_comment = []\n",
    "\n",
    "    verified_rate = []\n",
    "    spam_rate = []\n",
    "\n",
    "    for index, row in trainData.iterrows():\n",
    "        title = row['title']\n",
    "        comment = row['comment']\n",
    "        rate = row['rate']\n",
    "\n",
    "        if row['verification_status'] == 1:\n",
    "            verified_title.extend(title)\n",
    "            verified_comment.extend(comment)\n",
    "            verified_rate.append(rate)\n",
    "        else:\n",
    "            spam_title.extend(title)\n",
    "            spam_comment.extend(comment)\n",
    "            spam_rate.append(rate)\n",
    "    print(\"*************** spam and ver appended **\")\n",
    "\n",
    "    all_title = verified_title + spam_title\n",
    "    all_comment = verified_comment + spam_comment\n",
    "    all_rate = verified_rate + spam_rate\n",
    "    print(\"*************** all appended ***********\")\n",
    "\n",
    "    verified_title = collections.Counter(verified_title)\n",
    "    verified_comment = collections.Counter(verified_comment)\n",
    "    verified_rate = collections.Counter(verified_rate)\n",
    "    print(\"*************** verified count *********\")\n",
    "\n",
    "    spam_title = collections.Counter(spam_title)\n",
    "    spam_comment = collections.Counter(spam_comment)\n",
    "    spam_rate = collections.Counter(spam_rate)\n",
    "    print(\"*************** spam count *************\")\n",
    "\n",
    "    all_title = collections.Counter(all_title)\n",
    "    all_comment = collections.Counter(all_comment)\n",
    "    all_rate = collections.Counter(all_rate)\n",
    "    print(\"*************** all count **************\")\n",
    "\n",
    "    return (all_title, verified_title, spam_title), (all_comment, verified_comment, spam_comment), (\n",
    "        all_rate, verified_rate, spam_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    test_data['title'] = test_data['title'].apply(remove_extra_words)\n",
    "    test_data['comment'] = test_data['comment'].apply(remove_extra_words)\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "*************** read csv ***************\n",
      "*************** remove extra title *****\n",
      "*************** remove extra comment ***\n",
      "*************** spam and ver appended **\n",
      "*************** all appended ***********\n",
      "*************** verified count *********\n",
      "*************** spam count *************\n",
      "*************** all count **************\n",
      "############### Train pre process ###############\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "(allTitle, verifiedTitle, spamTitle), (allComment, verifiedComment, spamComment), (\n",
    "    allRate, verifiedRate, spamRate) = train()\n",
    "\n",
    "print('############### Train pre process ###############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "############### Test pre process  ###############\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "testData = test()\n",
    "\n",
    "print('############### Test pre process  ###############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "verTitleSum = sum(verifiedTitle.values())\n",
    "spamTitleSum = sum(spamTitle.values())\n",
    "\n",
    "verCommentSum = sum(verifiedComment.values())\n",
    "spamCommentSum = sum(spamComment.values())\n",
    "\n",
    "verRateSum = sum(verifiedRate.values())\n",
    "spamRateSum = sum(spamRate.values())\n",
    "\n",
    "titleLen = len(allTitle)\n",
    "allCommentLen = len(allComment)\n",
    "rateLen = len(allRate)\n",
    "\n",
    "answer_id = []\n",
    "answer_verification_status = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bayes(data, target: dict, _sum, length):\n",
    "    target_get = target[data] + 4\n",
    "    return target_get / (_sum + length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "############### Answer generated  ###############\n",
      "############### ans.csv generated  ###############\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for index, row in testData.iterrows():\n",
    "    title = row['title']\n",
    "    comment = row['comment']\n",
    "    rate = row['rate']\n",
    "    verified = 1\n",
    "    spam = 1\n",
    "    for t in title:\n",
    "        verified *= bayes(t, verifiedTitle, verTitleSum, titleLen)\n",
    "        spam *= bayes(t, spamTitle, spamTitleSum, titleLen)\n",
    "    for c in comment:\n",
    "        verified *= bayes(c, verifiedComment, verCommentSum, allCommentLen)\n",
    "        spam *= bayes(c, spamComment, spamCommentSum, allCommentLen)\n",
    "    verified *= bayes(rate, verifiedRate, verRateSum, rateLen)\n",
    "    spam *= bayes(rate, spamRate, spamRateSum, rateLen)\n",
    "\n",
    "    verification_status = 1 if verified > spam else 0\n",
    "\n",
    "    id = row['id']\n",
    "    answer_id.append(id)\n",
    "    answer_verification_status.append(verification_status)\n",
    "\n",
    "print('############### Answer generated  ###############')\n",
    "\n",
    "\n",
    "answer = {'id': answer_id, 'verification_status': answer_verification_status}\n",
    "df = DataFrame(answer, columns=['id', 'verification_status'])\n",
    "export_csv = df.to_csv('ans.csv', index=False)\n",
    "\n",
    "print('############### ans.csv generated  ###############')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}